{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68fd7b53",
   "metadata": {},
   "source": [
    "# Spancat Architecture Walkthrough\n",
    "\n",
    "In this notebook, we'll go through how the spancat architecture works. We have three goals:\n",
    "- Understand how each component of the spancat pipeline works.\n",
    "- Familiarize ourselves with working on the spaCy registry.\n",
    "- Figure out which component to udpate whenever we want to change something in Spancat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e908f3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your spaCy version is 3.3.1\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "print(f\"Your spaCy version is {spacy.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c003991",
   "metadata": {},
   "source": [
    "The spaCy registry is based on [`explosion/catalogue`](https://github.com/explosion/catalogue), and it allows us to call some of spaCy's components straight into our code. For convenience, I'll name the overall spaCy registry as `reg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9bae955",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = spacy.registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff2b40",
   "metadata": {},
   "source": [
    "Let's make sample spaCy Doc objects for debugging. In this case, let's have a short sentence and a longer one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7429f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "texts = [\n",
    "    \"A short sentence.\",\n",
    "    \"Multivariate analysis revealed that septic shock and bacteremia originating from lower respiratory tract infection were two independent risk factors for 30-day mortality.\"\n",
    "]\n",
    "docs = list(nlp.pipe(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e0ec6",
   "metadata": {},
   "source": [
    "## Initialize the spancat component \n",
    "\n",
    "In this section, we'll try to initialize the spancat component by creating various factories for its components. Note that we will be working backwards, starting from the `spancat` pipeline, and construct each component as we go along\n",
    "\n",
    "![](spancat_archi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90f02a",
   "metadata": {},
   "source": [
    "### Suggester Function (`suggester=ngram_suggester.v1`)\n",
    "\n",
    "The first thing we need to create is the suggester function. It may also be good to see how the suggester provides the suggested spans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3b1148",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggester_factory = reg.get(\"misc\", \"spacy.ngram_suggester.v1\")\n",
    "suggester = suggester_factory(sizes=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77583f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested = suggester(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db666e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0]), len(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac3191c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 72], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggested.lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95628fd8",
   "metadata": {},
   "source": [
    "The `suggested.lengths` are the windowed indices of the [spaCy Doc](https://spacy.io/api/doc) tokens. So in this case, it's looking at sizes of windows `1`, `2`, and `3`. If we inspect what they look like for the short sentence (note that it has four tokens: \"A\", \"short\", \"sentence\", \".\"), we'll have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4310f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span 0: A\n",
      "Span 1: short\n",
      "Span 2: sentence\n",
      "Span 3: .\n",
      "Span 4: A short\n",
      "Span 5: short sentence\n",
      "Span 6: sentence.\n",
      "Span 7: A short sentence\n",
      "Span 8: short sentence.\n"
     ]
    }
   ],
   "source": [
    "window_idxs = suggested.data[:suggested.lengths[0]].tolist()\n",
    "for idx, (start, end) in enumerate(window_idxs):\n",
    "    print(f\"Span {idx}: {docs[0][start:end]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5940c06",
   "metadata": {},
   "source": [
    "### Model (`model=spacy.SpanCategorizer.v1`)\n",
    "\n",
    "The `model`, on the other hand, requires us to pass a `tok2vec`, `reducer`, and `scorer` components. In addition,  the `tok2vec` architecture we want to use also requires us to pass something for the `embed` and `encode` parameters (check the dependency graph). Let's start with the `tok2vec` first and work our way from left to right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddd6031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tok2vec: get factories\n",
    "tok2vec_factory = reg.get(\"architectures\", \"spacy.Tok2Vec.v2\")\n",
    "embed_factory = reg.get(\"architectures\", \"spacy.MultiHashEmbed.v2\")\n",
    "encode_factory = reg.get(\"architectures\", \"spacy.MaxoutWindowEncoder.v2\")\n",
    "\n",
    "# tok2vec: construct components\n",
    "embed = embed_factory(\n",
    "    width=96,\n",
    "    rows=[5000, 2000, 1000, 1000],\n",
    "    attrs=[\"ORTH\", \"PREFIX\", \"SUFFIX\", \"SHAPE\"],\n",
    "    include_static_vectors=False,\n",
    ")\n",
    "\n",
    "encode = encode_factory(\n",
    "    width=96,\n",
    "    window_size=1,\n",
    "    maxout_pieces=3,\n",
    "    depth=4,\n",
    ")\n",
    "\n",
    "# tok2vec: assemble\n",
    "tok2vec = tok2vec_factory(embed=embed, encode=encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fdc3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducer: get factories\n",
    "reducer_factory = reg.get(\"layers\", \"spacy.mean_max_reducer.v1\")\n",
    "\n",
    "# reducer: construct components and assemble\n",
    "reducer = reducer_factory(hidden_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13491c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scorer: get factories\n",
    "scorer_factory = reg.get(\"layers\", \"spacy.LinearLogistic.v1\")\n",
    "\n",
    "# scorer: construct components and assemble\n",
    "scorer = scorer_factory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0847f5b",
   "metadata": {},
   "source": [
    "Now that we have the `tok2vec`, `reducer`, and `scorer`, we can assemble them together for the spancat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4986eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factory = reg.get(\"architectures\", \"spacy.SpanCategorizer.v1\")\n",
    "model = model_factory(tok2vec=tok2vec, reducer=reducer, scorer=scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143e0c1",
   "metadata": {},
   "source": [
    "### Pipeline (factory=`spancat`)\n",
    "\n",
    "Now that we have the `model` and `suggester`, we can finally assemble the `spancat` pipeline. There are other parameters we need to provide, like `nlp`, etc. but we don't need to construct any of them unlike the other two earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd1af0",
   "metadata": {},
   "source": [
    "Optionally, we can also add a `Scorer` (this is different from the scorer `LinearLogistic.v1`that affects the model) to store our results. We need to construct from a factory again but this should be quick and easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "843cce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_scorer_factory = reg.get(\"scorers\", \"spacy.spancat_scorer.v1\")\n",
    "spacy_scorer = spacy_scorer_factory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b957a3",
   "metadata": {},
   "source": [
    "What `spacy.spancat_scorer.v1` does is that it adds the `spans_sc_{}` values in the `spacy.Scorer` so that it gets reported during training and evaluation. Again, note that this only performs scoring and eval, the component itself does not affect the model, it only reports what the original scorer, `LinearLogistic.v1` has computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e812381",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_factory = reg.get(\"factories\", \"spancat\")\n",
    "pipeline = pipeline_factory(\n",
    "    nlp=nlp,  ## a blank:en pipeline\n",
    "    name=\"spancat\",\n",
    "    threshold=0.5,\n",
    "    spans_key=\"sc\",\n",
    "    max_positive=None,\n",
    "    # These are the two that we constructed earlier\n",
    "    model=model,\n",
    "    suggester=suggester,\n",
    "    # The optional spaCy scorer for storing the computed scores\n",
    "    scorer=spacy_scorer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43776cf",
   "metadata": {},
   "source": [
    "From here we can now access **anything** in the [SpanCategorizer pipeline](https://spacy.io/api/spancategorizer). For example, we can train our model by calling the `pipeline.update` function. However, it's more ideal to use the [Training Config system](https://spacy.io/usage/training) for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "921fabed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_loss??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f118f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
